{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drorb1987/mafat/blob/main/baseline_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-krTp6T8TeL"
      },
      "source": [
        "##Download training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHpZYXmQypb2",
        "outputId": "033c273f-1858-456f-f177-610f85274423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You selected mini dataset\n"
          ]
        }
      ],
      "source": [
        "#@title Click `Show code` in the code cell. { display-mode: \"form\" }\n",
        "\n",
        "dataset = \"mini dataset\" #@param [\"full dataset\", \"mini dataset\"]\n",
        "\n",
        "full_data = \"https://drive.google.com/file/d/14MDE3RUpRMeUJ8VpI5BMFAZG-xnfon7B/view?usp=sharing\"\n",
        "mini_data = \"https://drive.google.com/file/d/1PPVWxaiMsFALJBWUQIfkYZNFzhsv0gaa/view?usp=sharing\"\n",
        "url = mini_data\n",
        "print('You selected', dataset)\n",
        "if dataset == \"mini dataset\":\n",
        "    url = mini_data\n",
        "else:\n",
        "    url = full_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "NB7DwKXxEz5G",
        "outputId": "b5c3794c-23c4-4af3-aeab-3c6a704d6268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PPVWxaiMsFALJBWUQIfkYZNFzhsv0gaa\n",
            "To: /content/train_dataset.zip\n",
            "100%|██████████| 19.7M/19.7M [00:00<00:00, 35.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "gdown.download(url=url, output=\"train_dataset.zip\",quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlvHt6H9GRkX",
        "outputId": "796a9e55-06a8-4af1-f828-ae7f68bd02de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train_dataset.zip\n",
            "  inflating: metadata_train.csv      \n",
            "   creating: images/\n",
            "  inflating: images/126_0_0.tiff     \n",
            "  inflating: images/126_0_1280.tiff  \n",
            "  inflating: images/126_0_2560.tiff  \n",
            "  inflating: images/126_0_3840.tiff  \n",
            "  inflating: images/126_0_5120.tiff  \n",
            "  inflating: images/126_1280_5120.tiff  \n",
            "  inflating: images/72_0_0.tiff      \n",
            "  inflating: images/72_0_3840.tiff   \n",
            "   creating: labelTxt/\n",
            "  inflating: labelTxt/126_0_0.txt    \n",
            "  inflating: labelTxt/126_0_1280.txt  \n",
            "  inflating: labelTxt/126_0_2560.txt  \n",
            "  inflating: labelTxt/126_0_3840.txt  \n",
            "  inflating: labelTxt/126_0_5120.txt  \n",
            "  inflating: labelTxt/126_1280_5120.txt  \n",
            " extracting: labelTxt/72_0_0.txt     \n",
            " extracting: labelTxt/72_0_3840.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/train_dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK4qlrj8D0hk"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkHH7-5HOFNT"
      },
      "source": [
        "### modified spliting script based on the splitting script from mmrotate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWVj2ZIIOEop",
        "outputId": "bb511827-ca12-477b-dd83-8636a65c4d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing img_split.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile img_split.py\n",
        "# Copyright (c) OpenMMLab. All rights reserved.\n",
        "# Written by jbwang1997\n",
        "# Reference: https://github.com/jbwang1997/BboxToolkit\n",
        "\n",
        "import argparse\n",
        "import codecs\n",
        "import datetime\n",
        "import itertools\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "from functools import partial, reduce\n",
        "from math import ceil\n",
        "from multiprocessing import Manager, Pool\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "try:\n",
        "    import shapely.geometry as shgeo\n",
        "except ImportError:\n",
        "    shgeo = None\n",
        "\n",
        "\n",
        "def add_parser(parser):\n",
        "    \"\"\"Add arguments.\"\"\"\n",
        "    parser.add_argument(\n",
        "        '--base-json',\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help='json config file for split images')\n",
        "    parser.add_argument(\n",
        "        '--nproc', type=int, default=10, help='the procession number')\n",
        "\n",
        "    # argument for loading data\n",
        "    parser.add_argument(\n",
        "        '--img-dirs',\n",
        "        nargs='+',\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help='images dirs, must give a value')\n",
        "    parser.add_argument(\n",
        "        '--ann-dirs',\n",
        "        nargs='+',\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help='annotations dirs, optional')\n",
        "\n",
        "    # argument for splitting image\n",
        "    parser.add_argument(\n",
        "        '--sizes',\n",
        "        nargs='+',\n",
        "        type=int,\n",
        "        default=[1024],\n",
        "        help='the sizes of sliding windows')\n",
        "    parser.add_argument(\n",
        "        '--gaps',\n",
        "        nargs='+',\n",
        "        type=int,\n",
        "        default=[512],\n",
        "        help='the steps of sliding widnows')\n",
        "    parser.add_argument(\n",
        "        '--rates',\n",
        "        nargs='+',\n",
        "        type=float,\n",
        "        default=[1.],\n",
        "        help='same as DOTA devkit rate, but only change windows size')\n",
        "    parser.add_argument(\n",
        "        '--img-rate-thr',\n",
        "        type=float,\n",
        "        default=0.6,\n",
        "        help='the minimal rate of image in window and window')\n",
        "    parser.add_argument(\n",
        "        '--iof-thr',\n",
        "        type=float,\n",
        "        default=0.7,\n",
        "        help='the minimal iof between a object and a window')\n",
        "    parser.add_argument(\n",
        "        '--no-padding',\n",
        "        action='store_true',\n",
        "        help='not padding patches in regular size')\n",
        "    parser.add_argument(\n",
        "        '--padding-value',\n",
        "        nargs='+',\n",
        "        type=int,\n",
        "        default=[0],\n",
        "        help='padding value, 1 or channel number')\n",
        "\n",
        "    # argument for saving\n",
        "    parser.add_argument(\n",
        "        '--save-dir',\n",
        "        type=str,\n",
        "        default='.',\n",
        "        help='to save pkl and split images')\n",
        "    parser.add_argument(\n",
        "        '--save-ext',\n",
        "        type=str,\n",
        "        default='.png',\n",
        "        help='the extension of saving images')\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"Parse arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Splitting images')\n",
        "    add_parser(parser)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.base_json is not None:\n",
        "        with open(args.base_json, 'r') as f:\n",
        "            prior_config = json.load(f)\n",
        "\n",
        "        for action in parser._actions:\n",
        "            if action.dest not in prior_config or \\\n",
        "                    not hasattr(action, 'default'):\n",
        "                continue\n",
        "            action.default = prior_config[action.dest]\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    # assert arguments\n",
        "    assert args.img_dirs is not None, \"argument img_dirs can't be None\"\n",
        "    assert args.ann_dirs is None or len(args.ann_dirs) == len(args.img_dirs)\n",
        "    assert len(args.sizes) == len(args.gaps)\n",
        "    assert len(args.sizes) == 1 or len(args.rates) == 1\n",
        "    assert args.save_ext in ['.png', '.jpg', 'bmp', '.tif', '.tiff']\n",
        "    assert args.iof_thr >= 0 and args.iof_thr < 1\n",
        "    assert args.iof_thr >= 0 and args.iof_thr <= 1\n",
        "    assert not osp.exists(args.save_dir), \\\n",
        "        f'{osp.join(args.save_dir)} already exists'\n",
        "    return args\n",
        "\n",
        "\n",
        "def get_sliding_window(info, sizes, gaps, img_rate_thr):\n",
        "    \"\"\"Get sliding windows.\n",
        "\n",
        "    Args:\n",
        "        info (dict): Dict of image's width and height.\n",
        "        sizes (list): List of window's sizes.\n",
        "        gaps (list): List of window's gaps.\n",
        "        img_rate_thr (float): Threshold of window area divided by image area.\n",
        "\n",
        "    Returns:\n",
        "        list[np.array]: Information of valid windows.\n",
        "    \"\"\"\n",
        "    eps = 0.01\n",
        "    windows = []\n",
        "    width, height = info['width'], info['height']\n",
        "    for size, gap in zip(sizes, gaps):\n",
        "        assert size > gap, f'invaild size gap pair [{size} {gap}]'\n",
        "        step = size - gap\n",
        "\n",
        "        x_num = 1 if width <= size else ceil((width - size) / step + 1)\n",
        "        x_start = [step * i for i in range(x_num)]\n",
        "        if len(x_start) > 1 and x_start[-1] + size > width:\n",
        "            x_start[-1] = width - size\n",
        "\n",
        "        y_num = 1 if height <= size else ceil((height - size) / step + 1)\n",
        "        y_start = [step * i for i in range(y_num)]\n",
        "        if len(y_start) > 1 and y_start[-1] + size > height:\n",
        "            y_start[-1] = height - size\n",
        "\n",
        "        start = np.array(\n",
        "            list(itertools.product(x_start, y_start)), dtype=np.int64)\n",
        "        stop = start + size\n",
        "        windows.append(np.concatenate([start, stop], axis=1))\n",
        "    windows = np.concatenate(windows, axis=0)\n",
        "\n",
        "    img_in_wins = windows.copy()\n",
        "    img_in_wins[:, 0::2] = np.clip(img_in_wins[:, 0::2], 0, width)\n",
        "    img_in_wins[:, 1::2] = np.clip(img_in_wins[:, 1::2], 0, height)\n",
        "    img_areas = (img_in_wins[:, 2] - img_in_wins[:, 0]) * \\\n",
        "                (img_in_wins[:, 3] - img_in_wins[:, 1])\n",
        "    win_areas = (windows[:, 2] - windows[:, 0]) * \\\n",
        "                (windows[:, 3] - windows[:, 1])\n",
        "    img_rates = img_areas / win_areas\n",
        "    if not (img_rates > img_rate_thr).any():\n",
        "        max_rate = img_rates.max()\n",
        "        img_rates[abs(img_rates - max_rate) < eps] = 1\n",
        "    return windows[img_rates > img_rate_thr]\n",
        "\n",
        "\n",
        "def poly2hbb(polys):\n",
        "    \"\"\"Convert polygons to horizontal bboxes.\n",
        "\n",
        "    Args:\n",
        "        polys (np.array): Polygons with shape (N, 8)\n",
        "\n",
        "    Returns:\n",
        "        np.array: Horizontal bboxes.\n",
        "    \"\"\"\n",
        "    shape = polys.shape\n",
        "    polys = polys.reshape(*shape[:-1], shape[-1] // 2, 2)\n",
        "    lt_point = np.min(polys, axis=-2)\n",
        "    rb_point = np.max(polys, axis=-2)\n",
        "    return np.concatenate([lt_point, rb_point], axis=-1)\n",
        "\n",
        "\n",
        "def bbox_overlaps_iof(bboxes1, bboxes2, eps=1e-6):\n",
        "    \"\"\"Compute bbox overlaps (iof).\n",
        "\n",
        "    Args:\n",
        "        bboxes1 (np.array): Horizontal bboxes1.\n",
        "        bboxes2 (np.array): Horizontal bboxes2.\n",
        "        eps (float, optional): Defaults to 1e-6.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Overlaps.\n",
        "    \"\"\"\n",
        "    rows = bboxes1.shape[0]\n",
        "    cols = bboxes2.shape[0]\n",
        "\n",
        "    if rows * cols == 0:\n",
        "        return np.zeros((rows, cols), dtype=np.float32)\n",
        "\n",
        "    hbboxes1 = poly2hbb(bboxes1)\n",
        "    hbboxes2 = bboxes2\n",
        "    hbboxes1 = hbboxes1[:, None, :]\n",
        "    lt = np.maximum(hbboxes1[..., :2], hbboxes2[..., :2])\n",
        "    rb = np.minimum(hbboxes1[..., 2:], hbboxes2[..., 2:])\n",
        "    wh = np.clip(rb - lt, 0, np.inf)\n",
        "    h_overlaps = wh[..., 0] * wh[..., 1]\n",
        "\n",
        "    l, t, r, b = [bboxes2[..., i] for i in range(4)]\n",
        "    polys2 = np.stack([l, t, r, t, r, b, l, b], axis=-1)\n",
        "    if shgeo is None:\n",
        "        raise ImportError('Please run \"pip install shapely\" '\n",
        "                          'to install shapely first.')\n",
        "    sg_polys1 = [shgeo.Polygon(p) for p in bboxes1.reshape(rows, -1, 2)]\n",
        "    sg_polys2 = [shgeo.Polygon(p) for p in polys2.reshape(cols, -1, 2)]\n",
        "    overlaps = np.zeros(h_overlaps.shape)\n",
        "    for p in zip(*np.nonzero(h_overlaps)):\n",
        "        overlaps[p] = sg_polys1[p[0]].intersection(sg_polys2[p[-1]]).area\n",
        "    unions = np.array([p.area for p in sg_polys1], dtype=np.float32)\n",
        "    unions = unions[..., None]\n",
        "\n",
        "    unions = np.clip(unions, eps, np.inf)\n",
        "    outputs = overlaps / unions\n",
        "    if outputs.ndim == 1:\n",
        "        outputs = outputs[..., None]\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def get_window_obj(info, windows, iof_thr):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        info (dict): Dict of bbox annotations.\n",
        "        windows (np.array): information of sliding windows.\n",
        "        iof_thr (float): Threshold of overlaps between bbox and window.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: List of bbox annotations of every window.\n",
        "    \"\"\"\n",
        "    bboxes = info['ann']['bboxes']\n",
        "    iofs = bbox_overlaps_iof(bboxes, windows)\n",
        "\n",
        "    window_anns = []\n",
        "    for i in range(windows.shape[0]):\n",
        "        win_iofs = iofs[:, i]\n",
        "        pos_inds = np.nonzero(win_iofs >= iof_thr)[0].tolist()\n",
        "\n",
        "        win_ann = dict()\n",
        "        for k, v in info['ann'].items():\n",
        "            try:\n",
        "                win_ann[k] = v[pos_inds]\n",
        "            except TypeError:\n",
        "                win_ann[k] = [v[i] for i in pos_inds]\n",
        "        win_ann['trunc'] = win_iofs[pos_inds] < 1\n",
        "        window_anns.append(win_ann)\n",
        "    return window_anns\n",
        "\n",
        "\n",
        "def crop_and_save_img(info, windows, window_anns, img_dir, no_padding,\n",
        "                      padding_value, save_dir, anno_dir, img_ext):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        info (dict): Image's information.\n",
        "        windows (np.array): information of sliding windows.\n",
        "        window_anns (list[dict]): List of bbox annotations of every window.\n",
        "        img_dir (str): Path of images.\n",
        "        no_padding (bool): If True, no padding.\n",
        "        padding_value (tuple[int|float]): Padding value.\n",
        "        save_dir (str): Save filename.\n",
        "        anno_dir (str): Annotation filename.\n",
        "        img_ext (str): Picture suffix.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: Information of paths.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(osp.join(img_dir, info['filename']), -1)\n",
        "    # img = Image.open(osp.join(img_dir, info['filename']))\n",
        "    # img = np.asarray(img)\n",
        "    patch_infos = []\n",
        "    for i in range(windows.shape[0]):\n",
        "        patch_info = dict()\n",
        "        for k, v in info.items():\n",
        "            if k not in ['id', 'fileanme', 'width', 'height', 'ann']:\n",
        "                patch_info[k] = v\n",
        "\n",
        "        window = windows[i]\n",
        "        x_start, y_start, x_stop, y_stop = window.tolist()\n",
        "        patch_info['x_start'] = x_start\n",
        "        patch_info['y_start'] = y_start\n",
        "        patch_info['id'] = \\\n",
        "            info['id'] + '__' + str(x_stop - x_start) + \\\n",
        "            '__' + str(x_start) + '___' + str(y_start)\n",
        "        patch_info['ori_id'] = info['id']\n",
        "\n",
        "        ann = window_anns[i]\n",
        "        ann['bboxes'] = translate(ann['bboxes'], -x_start, -y_start)\n",
        "        patch_info['ann'] = ann\n",
        "\n",
        "        patch = img[y_start:y_stop, x_start:x_stop]\n",
        "        if not no_padding:\n",
        "            height = y_stop - y_start\n",
        "            width = x_stop - x_start\n",
        "            if height > patch.shape[0] or width > patch.shape[1]:\n",
        "                padding_patch = np.empty((height, width, patch.shape[-1]),\n",
        "                                         dtype=np.uint8)\n",
        "                if not isinstance(padding_value, (int, float)):\n",
        "                    assert len(padding_value) == patch.shape[-1]\n",
        "                padding_patch[...] = padding_value\n",
        "                padding_patch[:patch.shape[0], :patch.shape[1], ...] = patch\n",
        "                patch = padding_patch\n",
        "        patch_info['height'] = patch.shape[0]\n",
        "        patch_info['width'] = patch.shape[1]\n",
        "\n",
        "        cv2.imwrite(osp.join(save_dir, patch_info['id'] + img_ext), patch)\n",
        "        patch_info['filename'] = patch_info['id'] + img_ext\n",
        "        patch_infos.append(patch_info)\n",
        "\n",
        "        bboxes_num = patch_info['ann']['bboxes'].shape[0]\n",
        "        outdir = os.path.join(anno_dir, patch_info['id'] + '.txt')\n",
        "\n",
        "        with codecs.open(outdir, 'w', 'utf-8') as f_out:\n",
        "            if bboxes_num == 0:\n",
        "                pass\n",
        "            else:\n",
        "                for idx in range(bboxes_num):\n",
        "                    obj = patch_info['ann']\n",
        "                    outline = ' '.join(list(map(str, obj['bboxes'][idx])))\n",
        "                    diffs = str(\n",
        "                        obj['diffs'][idx]) if not obj['trunc'][idx] else '2'\n",
        "                    outline = outline + ' ' + obj['labels'][idx] + ' ' + diffs\n",
        "                    f_out.write(outline + '\\n')\n",
        "\n",
        "    return patch_infos\n",
        "\n",
        "\n",
        "def single_split(arguments, sizes, gaps, img_rate_thr, iof_thr, no_padding,\n",
        "                 padding_value, save_dir, anno_dir, img_ext, lock, prog, total,\n",
        "                 logger):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        arguments (object): Parameters.\n",
        "        sizes (list): List of window's sizes.\n",
        "        gaps (list): List of window's gaps.\n",
        "        img_rate_thr (float): Threshold of window area divided by image area.\n",
        "        iof_thr (float): Threshold of overlaps between bbox and window.\n",
        "        no_padding (bool): If True, no padding.\n",
        "        padding_value (tuple[int|float]): Padding value.\n",
        "        save_dir (str): Save filename.\n",
        "        anno_dir (str): Annotation filename.\n",
        "        img_ext (str): Picture suffix.\n",
        "        lock (object): Lock of Manager.\n",
        "        prog (object): Progress of Manager.\n",
        "        total (object): Length of infos.\n",
        "        logger (object): Logger.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: Information of paths.\n",
        "    \"\"\"\n",
        "    info, img_dir = arguments\n",
        "    windows = get_sliding_window(info, sizes, gaps, img_rate_thr)\n",
        "    window_anns = get_window_obj(info, windows, iof_thr)\n",
        "    patch_infos = crop_and_save_img(info, windows, window_anns, img_dir,\n",
        "                                    no_padding, padding_value, save_dir,\n",
        "                                    anno_dir, img_ext)\n",
        "    assert patch_infos\n",
        "\n",
        "    lock.acquire()\n",
        "    prog.value += 1\n",
        "    msg = f'({prog.value / total:3.1%} {prog.value}:{total})'\n",
        "    msg += ' - ' + f\"Filename: {info['filename']}\"\n",
        "    msg += ' - ' + f\"width: {info['width']:<5d}\"\n",
        "    msg += ' - ' + f\"height: {info['height']:<5d}\"\n",
        "    msg += ' - ' + f\"Objects: {len(info['ann']['bboxes']):<5d}\"\n",
        "    msg += ' - ' + f'Patches: {len(patch_infos)}'\n",
        "    logger.info(msg)\n",
        "    lock.release()\n",
        "\n",
        "    return patch_infos\n",
        "\n",
        "\n",
        "def setup_logger(log_path):\n",
        "    \"\"\"Setup logger.\n",
        "\n",
        "    Args:\n",
        "        log_path (str): Path of log.\n",
        "\n",
        "    Returns:\n",
        "        object: Logger.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger('img split')\n",
        "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "    now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    log_path = osp.join(log_path, now + '.log')\n",
        "    handlers = [logging.StreamHandler(), logging.FileHandler(log_path, 'w')]\n",
        "\n",
        "    for handler in handlers:\n",
        "        handler.setFormatter(formatter)\n",
        "        handler.setLevel(logging.INFO)\n",
        "        logger.addHandler(handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    return logger\n",
        "\n",
        "\n",
        "def translate(bboxes, x, y):\n",
        "    \"\"\"Map bboxes from window coordinate back to original coordinate.\n",
        "\n",
        "    Args:\n",
        "        bboxes (np.array): bboxes with window coordinate.\n",
        "        x (float): Deviation value of x-axis.\n",
        "        y (float): Deviation value of y-axis\n",
        "\n",
        "    Returns:\n",
        "        np.array: bboxes with original coordinate.\n",
        "    \"\"\"\n",
        "    dim = bboxes.shape[-1]\n",
        "    translated = bboxes + np.array([x, y] * int(dim / 2), dtype=np.float32)\n",
        "    return translated\n",
        "\n",
        "\n",
        "def load_dota(img_dir, ann_dir=None, nproc=10):\n",
        "    \"\"\"Load DOTA dataset.\n",
        "\n",
        "    Args:\n",
        "        img_dir (str): Path of images.\n",
        "        ann_dir (str): Path of annotations.\n",
        "        nproc (int): number of processes.\n",
        "\n",
        "    Returns:\n",
        "        list: Dataset's contents.\n",
        "    \"\"\"\n",
        "    assert osp.isdir(img_dir), f'The {img_dir} is not an existing dir!'\n",
        "    assert ann_dir is None or osp.isdir(\n",
        "        ann_dir), f'The {ann_dir} is not an existing dir!'\n",
        "\n",
        "    print('Starting loading DOTA dataset information.')\n",
        "    start_time = time.time()\n",
        "    _load_func = partial(_load_dota_single, img_dir=img_dir, ann_dir=ann_dir)\n",
        "    if nproc > 1:\n",
        "        pool = Pool(nproc)\n",
        "        contents = pool.map(_load_func, os.listdir(img_dir))\n",
        "        pool.close()\n",
        "    else:\n",
        "        contents = list(map(_load_func, os.listdir(img_dir)))\n",
        "    contents = [c for c in contents if c is not None]\n",
        "    end_time = time.time()\n",
        "    print(f'Finishing loading DOTA, get {len(contents)} iamges,',\n",
        "          f'using {end_time - start_time:.3f}s.')\n",
        "\n",
        "    return contents\n",
        "\n",
        "\n",
        "def _load_dota_single(imgfile, img_dir, ann_dir):\n",
        "    \"\"\"Load DOTA's single image.\n",
        "\n",
        "    Args:\n",
        "        imgfile (str): Filename of single image.\n",
        "        img_dir (str): Path of images.\n",
        "        ann_dir (str): Path of annotations.\n",
        "\n",
        "    Returns:\n",
        "        dict: Content of single image.\n",
        "    \"\"\"\n",
        "    img_id, ext = osp.splitext(imgfile)\n",
        "    if ext not in ['.jpg', '.JPG', '.png', '.tif', '.bmp', '.tiff']:\n",
        "        return None\n",
        "\n",
        "    imgpath = osp.join(img_dir, imgfile)\n",
        "    size = Image.open(imgpath).size\n",
        "    txtfile = None if ann_dir is None else osp.join(ann_dir, img_id + '.txt')\n",
        "    content = _load_dota_txt(txtfile)\n",
        "\n",
        "    content.update(\n",
        "        dict(width=size[0], height=size[1], filename=imgfile, id=img_id))\n",
        "    return content\n",
        "\n",
        "\n",
        "def _load_dota_txt(txtfile):\n",
        "    \"\"\"Load DOTA's txt annotation.\n",
        "\n",
        "    Args:\n",
        "        txtfile (str): Filename of single txt annotation.\n",
        "\n",
        "    Returns:\n",
        "        dict: Annotation of single image.\n",
        "    \"\"\"\n",
        "    gsd, bboxes, labels, diffs = None, [], [], []\n",
        "    if txtfile is None:\n",
        "        pass\n",
        "    elif not osp.isfile(txtfile):\n",
        "        print(f\"Can't find {txtfile}, treated as empty txtfile\")\n",
        "    else:\n",
        "        with open(txtfile, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith('gsd'):\n",
        "                    num = line.split(':')[-1]\n",
        "                    try:\n",
        "                        gsd = float(num)\n",
        "                    except ValueError:\n",
        "                        gsd = None\n",
        "                    continue\n",
        "\n",
        "                items = line.split(' ')\n",
        "                if len(items) >= 9:\n",
        "                    bboxes.append([float(i) for i in items[:8]])\n",
        "                    labels.append(items[8])\n",
        "                    diffs.append(int(items[9]) if len(items) == 10 else 0)\n",
        "\n",
        "    bboxes = np.array(bboxes, dtype=np.float32) if bboxes else \\\n",
        "        np.zeros((0, 8), dtype=np.float32)\n",
        "    diffs = np.array(diffs, dtype=np.int64) if diffs else \\\n",
        "        np.zeros((0,), dtype=np.int64)\n",
        "    ann = dict(bboxes=bboxes, labels=labels, diffs=diffs)\n",
        "    return dict(gsd=gsd, ann=ann)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of image split.\"\"\"\n",
        "    args = parse_args()\n",
        "\n",
        "    if args.ann_dirs is None:\n",
        "        args.ann_dirs = [None for _ in range(len(args.img_dirs))]\n",
        "    padding_value = args.padding_value[0] \\\n",
        "        if len(args.padding_value) == 1 else args.padding_value\n",
        "    sizes, gaps = [], []\n",
        "    for rate in args.rates:\n",
        "        sizes += [int(size / rate) for size in args.sizes]\n",
        "        gaps += [int(gap / rate) for gap in args.gaps]\n",
        "    save_imgs = osp.join(args.save_dir, 'images')\n",
        "    save_files = osp.join(args.save_dir, 'annfiles')\n",
        "    os.makedirs(save_imgs)\n",
        "    os.makedirs(save_files)\n",
        "    logger = setup_logger(args.save_dir)\n",
        "\n",
        "    print('Loading original data!!!')\n",
        "    infos, img_dirs = [], []\n",
        "    for img_dir, ann_dir in zip(args.img_dirs, args.ann_dirs):\n",
        "        _infos = load_dota(img_dir=img_dir, ann_dir=ann_dir, nproc=args.nproc)\n",
        "        _img_dirs = [img_dir for _ in range(len(_infos))]\n",
        "        infos.extend(_infos)\n",
        "        img_dirs.extend(_img_dirs)\n",
        "\n",
        "    print('Start splitting images!!!')\n",
        "    start = time.time()\n",
        "    manager = Manager()\n",
        "    worker = partial(\n",
        "        single_split,\n",
        "        sizes=sizes,\n",
        "        gaps=gaps,\n",
        "        img_rate_thr=args.img_rate_thr,\n",
        "        iof_thr=args.iof_thr,\n",
        "        no_padding=args.no_padding,\n",
        "        padding_value=padding_value,\n",
        "        save_dir=save_imgs,\n",
        "        anno_dir=save_files,\n",
        "        img_ext=args.save_ext,\n",
        "        lock=manager.Lock(),\n",
        "        prog=manager.Value('i', 0),\n",
        "        total=len(infos),\n",
        "        logger=logger)\n",
        "\n",
        "    if args.nproc > 1:\n",
        "        pool = Pool(args.nproc)\n",
        "        patch_infos = pool.map(worker, zip(infos, img_dirs))\n",
        "        pool.close()\n",
        "    else:\n",
        "        patch_infos = list(map(worker, zip(infos, img_dirs)))\n",
        "\n",
        "    patch_infos = reduce(lambda x, y: x + y, patch_infos)\n",
        "    stop = time.time()\n",
        "    print(f'Finish splitting images in {int(stop - start)} second!!!')\n",
        "    print(f'Total images number: {len(patch_infos)}')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqCIq6T8P958",
        "outputId": "e4db560d-068e-4f1e-86e8-8fe2010caf05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing split_config.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile split_config.json\n",
        "{\n",
        "    \"nproc\": 1,\n",
        "    \"img_dirs\": [\n",
        "      \"images\"\n",
        "    ],\n",
        "    \"ann_dirs\": [\n",
        "      \"labelTxt\"\n",
        "    ],\n",
        "    \"sizes\": [\n",
        "      640\n",
        "    ],\n",
        "    \"gaps\": [\n",
        "      320\n",
        "    ],\n",
        "    \"rates\": [\n",
        "      1.0\n",
        "    ],\n",
        "    \"img_rate_thr\": 0.6,\n",
        "    \"iof_thr\": 0.7,\n",
        "    \"no_padding\": false,\n",
        "    \"padding_value\": [\n",
        "      0,\n",
        "      0,\n",
        "      0\n",
        "    ],\n",
        "    \"save_dir\": \"split_640_640\",\n",
        "    \"save_ext\": \".tiff\"\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDRzOpzHHTyb"
      },
      "source": [
        "### Split the frames to 640X640 size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ00ULRvHa9N",
        "outputId": "7f194eae-72c1-48d1-b168-47dac69a97fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading original data!!!\n",
            "Starting loading DOTA dataset information.\n",
            "Finishing loading DOTA, get 8 iamges, using 0.034s.\n",
            "Start splitting images!!!\n",
            "2023-02-08 13:43:40,537 - (12.5% 1:8) - Filename: 126_0_1280.tiff - width: 1280  - height: 1280  - Objects: 12    - Patches: 9\n",
            "2023-02-08 13:43:40,742 - (25.0% 2:8) - Filename: 126_0_2560.tiff - width: 1280  - height: 1280  - Objects: 10    - Patches: 9\n",
            "2023-02-08 13:43:40,969 - (37.5% 3:8) - Filename: 126_0_0.tiff - width: 1280  - height: 1280  - Objects: 15    - Patches: 9\n",
            "2023-02-08 13:43:41,206 - (50.0% 4:8) - Filename: 126_1280_5120.tiff - width: 1280  - height: 1280  - Objects: 26    - Patches: 9\n",
            "2023-02-08 13:43:41,416 - (62.5% 5:8) - Filename: 72_0_0.tiff - width: 1280  - height: 1280  - Objects: 0     - Patches: 9\n",
            "2023-02-08 13:43:41,701 - (75.0% 6:8) - Filename: 72_0_3840.tiff - width: 1280  - height: 1280  - Objects: 0     - Patches: 9\n",
            "2023-02-08 13:43:42,019 - (87.5% 7:8) - Filename: 126_0_5120.tiff - width: 1280  - height: 1280  - Objects: 46    - Patches: 9\n",
            "2023-02-08 13:43:42,477 - (100.0% 8:8) - Filename: 126_0_3840.tiff - width: 1280  - height: 1280  - Objects: 8     - Patches: 9\n",
            "Finish splitting images in 2 second!!!\n",
            "Total images number: 72\n"
          ]
        }
      ],
      "source": [
        "!python img_split.py --base-json \"split_config.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXeb_p0PN3LZ"
      },
      "source": [
        "### split dataset to train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG-PgJiHN9_l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import sample\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgdIQqyNDy6b"
      },
      "outputs": [],
      "source": [
        "data_root = './split_640_640'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wekN1vcPEQLI"
      },
      "outputs": [],
      "source": [
        "images_paths = np.asarray(sorted(os.listdir(os.path.join(data_root, \"images\"))))\n",
        "labels_paths = np.asarray(sorted(os.listdir(os.path.join(data_root, \"annfiles\"))))\n",
        "\n",
        "l = len(images_paths) #length of data \n",
        "f = int(0.8 * l)  #number of elements you need\n",
        "indices = sample(range(l),f)\n",
        "\n",
        "images_paths_train = images_paths[indices]\n",
        "labels_paths_train = labels_paths[indices]\n",
        "\n",
        "images_paths_val = np.delete(images_paths, indices)\n",
        "labels_paths_val = np.delete(labels_paths, indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY2--Gp6EhHB"
      },
      "outputs": [],
      "source": [
        "#create folders with splits\n",
        "\n",
        "# create folders\n",
        "os.makedirs(os.path.join(\"train\", \"images\"))\n",
        "os.makedirs(os.path.join(\"train\", \"labelTxt\"))\n",
        "\n",
        "os.makedirs(os.path.join(\"val\", \"images\"))\n",
        "os.makedirs(os.path.join(\"val\", \"labelTxt\"))\n",
        "\n",
        "# move files to folders\n",
        "for img_path, lbl_path in zip(images_paths_train, labels_paths_train):\n",
        "    src = os.path.join(data_root, \"images\", img_path)\n",
        "    dst = os.path.join(\"train\", \"images\", img_path)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "    src = os.path.join(data_root, \"annfiles\", lbl_path)\n",
        "    dst = os.path.join(\"train\", \"labelTxt\", lbl_path)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# move files to folders\n",
        "for img_path, lbl_path in zip(images_paths_val, labels_paths_val):\n",
        "    src = os.path.join(data_root, \"images\", img_path)\n",
        "    dst = os.path.join(\"val\", \"images\", img_path)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "    src = os.path.join(data_root, \"annfiles\", lbl_path)\n",
        "    dst = os.path.join(\"val\", \"labelTxt\", lbl_path)\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdp7mbErQrEb"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJVluHjBf5Un"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affBf6Vz_0Ql",
        "outputId": "7979eee8-a421-4c86-a8e0-6afd6c5d0b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKeky_Wu72o8",
        "outputId": "4392874f-1342-4f38-abbf-167d6ff69a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.12.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp38-cp38-linux_x86_64.whl (1904.8 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1904771072 bytes == 0x260c000 @  0x7f5f7a8da680 0x7f5f7a8fb824 0x5b3128 0x5bbc90 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2380963840 bytes == 0x73e94000 @  0x7f5f7a8da680 0x7f5f7a8fada2 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a\n",
            "tcmalloc: large alloc 1904771072 bytes == 0x260c000 @  0x7f5f7a8da680 0x7f5f7a8fb824 0x5f97c1 0x5f8ecc 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x50b32c 0x5f6b7b 0x66731d 0x5f6706 0x571143 0x50b22e 0x570b82 0x569d8a 0x50b3a0 0x570b82 0x569d8a 0x50b3a0 0x56cc92 0x501044 0x56be83 0x501044 0x56be83 0x501044 0x56be83 0x5f5ee6\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m899.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl (23.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.1+cu116) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu116) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu116) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu116) (1.21.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu116) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu116) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu116) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu116) (1.24.3)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1+cu116 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1+cu116 torchvision-0.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pP9a2Uz_3p7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9127290-a2e6-4ba0-94be-a6ee3f6fec4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.5-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip>=19.3 in /usr/local/lib/python3.8/dist-packages (from openmim) (22.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openmim) (2.25.1)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.8/dist-packages (from openmim) (7.1.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from openmim) (1.3.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (3.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (6.0)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich->openmim) (4.4.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown->model-index->openmim) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.11.0)\n",
            "Installing collected packages: pygments, ordered-set, mdurl, colorama, markdown-it-py, rich, model-index, openmim\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 markdown-it-py-2.1.0 mdurl-0.1.2 model-index-0.1.11 openmim-0.3.5 ordered-set-4.1.0 pygments-2.14.0 rich-13.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu116/torch1.12.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu116/torch1.12.0/mmcv_full-1.7.1-cp38-cp38-manylinux1_x86_64.whl (43.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu116/torch1.12.0/index.html\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-2.28.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmdet) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmdet) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from mmdet) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mmdet) (1.7.3)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mmdet) (1.15.0)\n",
            "Requirement already satisfied: mmcv-full>=1.3.17 in /usr/local/lib/python3.8/dist-packages (from mmdet) (1.7.1)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (7.1.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (6.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.8/dist-packages (from mmcv-full>=1.3.17->mmdet) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet) (0.11.0)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-2.28.1 terminaltables-3.1.10\n",
            "Cloning into 'mmrotate'...\n",
            "remote: Enumerating objects: 3462, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 3462 (delta 11), reused 14 (delta 5), pack-reused 3410\u001b[K\n",
            "Receiving objects: 100% (3462/3462), 22.16 MiB | 32.85 MiB/s, done.\n",
            "Resolving deltas: 100% (2084/2084), done.\n",
            "/content/mmrotate\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmrotate\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting e2cnn\n",
            "  Downloading e2cnn-0.2.2-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (3.2.2)\n",
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (1.7.1)\n",
            "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (2.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (1.15.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (3.1.10)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from mmrotate==0.3.4) (1.12.1+cu116)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.7.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from e2cnn->mmrotate==0.3.4) (1.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmrotate==0.3.4) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmrotate==0.3.4) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmrotate==0.3.4) (0.11.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (21.3)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.32.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full->mmrotate==0.3.4) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->mmrotate==0.3.4) (4.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.2.1)\n",
            "Installing collected packages: e2cnn, mmrotate\n",
            "  Running setup.py develop for mmrotate\n",
            "Successfully installed e2cnn-0.2.2 mmrotate-0.3.4\n"
          ]
        }
      ],
      "source": [
        "# Install MMCV and MMDetection using MIM.\n",
        "!pip3 install -U openmim\n",
        "!mim install mmcv-full\n",
        "!mim install mmdet\n",
        "\n",
        "# Install MMRotate from the source.\n",
        "!git clone https://github.com/open-mmlab/mmrotate.git\n",
        "%cd mmrotate\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRGP4OSr8YYC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from random import sample\n",
        "import shutil\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFPaoIp2CmSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90d63a6-9807-4bf8-8377-74b8246826cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.4\n",
            "2.28.1\n",
            "11.6\n",
            "GCC 9.3\n"
          ]
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()\n",
        "\n",
        "# Check MMRotate installation\n",
        "import mmrotate\n",
        "print(mmrotate.__version__)\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifKK_MNzDjM9"
      },
      "source": [
        "### Download pre-trained weights and config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRPBB9wf3goj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e37e249-1eb8-4684-af0b-652befb5404e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiHmoq0JDUVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbed020-57b7-4707-fefd-76f897ba1ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n",
            "processing redet_re50_refpn_1x_dota_ms_rr_le90...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 MiB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth to /content\u001b[0m\n",
            "\u001b[32mSuccessfully dumped redet_re50_refpn_1x_dota_ms_rr_le90.py to /content\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# We use mim to download the pre-trained checkpoints for inference and finetuning.\n",
        "!mim download mmrotate --config redet_re50_refpn_1x_dota_ms_rr_le90 --dest ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw59UK_JDspH"
      },
      "source": [
        "### Define classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_XGfK-PDYy2"
      },
      "outputs": [],
      "source": [
        "# classes in dataset\n",
        "CLASSES_ALL = ('small_vehicle','bus','medium_vehicle','large_vehicle',\n",
        "     'double_trailer_truck','small_aircraft','large_aircraft','small_vessel','medium_vessel','large_vessel',\n",
        "     'heavy_equipment', 'container','pylon', )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KUbahHYgSJv"
      },
      "source": [
        "### Define custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az2jydzhgWpZ"
      },
      "outputs": [],
      "source": [
        "from mmrotate.datasets.builder import ROTATED_DATASETS, PIPELINES\n",
        "from mmrotate.datasets.dota import DOTADataset\n",
        "import glob\n",
        "import numpy as np\n",
        "from mmrotate.core import poly2obb_np\n",
        "import os\n",
        "\n",
        "from mmdet.datasets.pipelines import LoadImageFromFile\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "@ROTATED_DATASETS.register_module()\n",
        "class MAFATDataset(DOTADataset):\n",
        "    \"\"\"MAFAT dataset for detection.\"\"\"\n",
        "\n",
        "    CLASSES = CLASSES_ALL\n",
        "    \n",
        "    def load_annotations(self, ann_folder):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                ann_folder: folder that contains DOTA v1 annotations txt files\n",
        "        \"\"\"\n",
        "        cls_map = {c: i\n",
        "                   for i, c in enumerate(self.CLASSES)\n",
        "                   }  # in mmdet v2.0 label is 0-based\n",
        "        ann_files = glob.glob(ann_folder + '/*.txt')\n",
        "        data_infos = []\n",
        "        if not ann_files:  # test phase\n",
        "            ann_files = glob.glob(ann_folder + '/*.tiff')\n",
        "            for ann_file in ann_files:\n",
        "                data_info = {}\n",
        "                img_id = osp.split(ann_file)[1][:-4]\n",
        "                img_name = img_id + '.tiff'\n",
        "                data_info['filename'] = img_name\n",
        "                data_info['ann'] = {}\n",
        "                data_info['ann']['bboxes'] = []\n",
        "                data_info['ann']['labels'] = []\n",
        "                data_infos.append(data_info)\n",
        "        else:\n",
        "            for ann_file in ann_files:\n",
        "                data_info = {}\n",
        "                img_id = osp.split(ann_file)[1][:-4]\n",
        "                img_name = img_id + '.tiff'\n",
        "                data_info['filename'] = img_name\n",
        "                data_info['ann'] = {}\n",
        "                gt_bboxes = []\n",
        "                gt_labels = []\n",
        "                gt_polygons = []\n",
        "                gt_bboxes_ignore = []\n",
        "                gt_labels_ignore = []\n",
        "                gt_polygons_ignore = []\n",
        "\n",
        "                if os.path.getsize(ann_file) == 0 and self.filter_empty_gt:\n",
        "                    continue\n",
        "\n",
        "                with open(ann_file) as f:\n",
        "                    s = f.readlines()\n",
        "                    for si in s:\n",
        "                        bbox_info = si.split()\n",
        "                        poly = np.array(bbox_info[:8], dtype=np.float32)\n",
        "                        try:\n",
        "                            x, y, w, h, a = poly2obb_np(poly, self.version)\n",
        "                        except:  # noqa: E722\n",
        "                            continue\n",
        "                        cls_name = bbox_info[8]\n",
        "                        # difficulty = int(bbox_info[9])\n",
        "                        difficulty = 0\n",
        "                        label = cls_map[cls_name]\n",
        "                        if difficulty > self.difficulty:\n",
        "                            pass\n",
        "                        else:\n",
        "                            gt_bboxes.append([x, y, w, h, a])\n",
        "                            gt_labels.append(label)\n",
        "                            gt_polygons.append(poly)\n",
        "\n",
        "                if gt_bboxes:\n",
        "                    data_info['ann']['bboxes'] = np.array(\n",
        "                        gt_bboxes, dtype=np.float32)\n",
        "                    data_info['ann']['labels'] = np.array(\n",
        "                        gt_labels, dtype=np.int64)\n",
        "                    data_info['ann']['polygons'] = np.array(\n",
        "                        gt_polygons, dtype=np.float32)\n",
        "                else:\n",
        "                    data_info['ann']['bboxes'] = np.zeros((0, 5),\n",
        "                                                          dtype=np.float32)\n",
        "                    data_info['ann']['labels'] = np.array([], dtype=np.int64)\n",
        "                    data_info['ann']['polygons'] = np.zeros((0, 8),\n",
        "                                                            dtype=np.float32)\n",
        "\n",
        "                if gt_polygons_ignore:\n",
        "                    data_info['ann']['bboxes_ignore'] = np.array(\n",
        "                        gt_bboxes_ignore, dtype=np.float32)\n",
        "                    data_info['ann']['labels_ignore'] = np.array(\n",
        "                        gt_labels_ignore, dtype=np.int64)\n",
        "                    data_info['ann']['polygons_ignore'] = np.array(\n",
        "                        gt_polygons_ignore, dtype=np.float32)\n",
        "                else:\n",
        "                    data_info['ann']['bboxes_ignore'] = np.zeros(\n",
        "                        (0, 5), dtype=np.float32)\n",
        "                    data_info['ann']['labels_ignore'] = np.array(\n",
        "                        [], dtype=np.int64)\n",
        "                    data_info['ann']['polygons_ignore'] = np.zeros(\n",
        "                        (0, 8), dtype=np.float32)\n",
        "\n",
        "                data_infos.append(data_info)\n",
        "\n",
        "        self.img_ids = [*map(lambda x: x['filename'][:-4], data_infos)]\n",
        "        return data_infos\n",
        "    \n",
        "   \n",
        "@PIPELINES.register_module()\n",
        "class LoadImageFromFilePIL(LoadImageFromFile):\n",
        "    \"\"\"Load an image from file using PIL Image.\n",
        "        Images are 16 bit grayscale tiff files, stacked to a 3 channel to fit the DNN\"\"\"\n",
        "\n",
        "    def __call__(self, results):\n",
        "        \"\"\"Call functions to load image and get image meta information.\n",
        "\n",
        "        Args:\n",
        "            results (dict): Result dict from :obj:`mmdet.CustomDataset`.\n",
        "\n",
        "        Returns:\n",
        "            dict: The dict contains loaded image and meta information.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.file_client is None:\n",
        "            self.file_client = mmcv.FileClient(**self.file_client_args)\n",
        "\n",
        "        if results['img_prefix'] is not None:\n",
        "            filename = osp.join(results['img_prefix'],\n",
        "                                results['img_info']['filename'])\n",
        "        else:\n",
        "            filename = results['img_info']['filename']\n",
        "\n",
        "        img = cv2.imread(filename, -1)\n",
        "        img = np.stack((img,)*3, axis=-1)\n",
        "        if self.to_float32:\n",
        "            img = img.astype(np.float32)\n",
        "\n",
        "        results['filename'] = filename\n",
        "        results['ori_filename'] = results['img_info']['filename']\n",
        "        results['img'] = img\n",
        "        results['img_shape'] = img.shape\n",
        "        results['ori_shape'] = img.shape\n",
        "        results['img_fields'] = ['img']\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HFeWHcnhHmS"
      },
      "source": [
        "### Modify the config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EQLh7RZhJH3"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('redet_re50_refpn_1x_dota_ms_rr_le90.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEA3NEi0hOZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a08798-7efc-4799-fa80-eb78ecfa08c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "dataset_type = 'MAFATDataset'\n",
            "data_root = './'\n",
            "img_norm_cfg = dict(\n",
            "    type='Normalize',\n",
            "    mean=[795.0878, 795.0878, 795.0878],\n",
            "    std=[460.0955, 460.0955, 460.0955],\n",
            "    to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFilePIL', color_type='unchanged'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='RResize', img_scale=(1024, 1024)),\n",
            "    dict(\n",
            "        type='RRandomFlip',\n",
            "        flip_ratio=[0.25, 0.25, 0.25],\n",
            "        direction=['horizontal', 'vertical', 'diagonal'],\n",
            "        version='le90'),\n",
            "    dict(\n",
            "        type='PolyRandomRotate',\n",
            "        rotate_ratio=0.5,\n",
            "        angles_range=180,\n",
            "        auto_bound=False,\n",
            "        rect_classes=[9, 11],\n",
            "        version='le90'),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFilePIL', color_type='unchanged'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1024, 1024),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='RResize'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='MAFATDataset',\n",
            "        ann_file='labelTxt',\n",
            "        img_prefix='images',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='RResize', img_scale=(1024, 1024)),\n",
            "            dict(\n",
            "                type='RRandomFlip',\n",
            "                flip_ratio=[0.25, 0.25, 0.25],\n",
            "                direction=['horizontal', 'vertical', 'diagonal'],\n",
            "                version='le90'),\n",
            "            dict(\n",
            "                type='PolyRandomRotate',\n",
            "                rotate_ratio=0.5,\n",
            "                angles_range=180,\n",
            "                auto_bound=False,\n",
            "                rect_classes=[9, 11],\n",
            "                version='le90'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[795.0878, 795.0878, 795.0878],\n",
            "                std=[460.0955, 460.0955, 460.0955],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ],\n",
            "        version='le90',\n",
            "        data_root='./train'),\n",
            "    val=dict(\n",
            "        type='MAFATDataset',\n",
            "        ann_file='labelTxt',\n",
            "        img_prefix='images',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1024, 1024),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='RResize'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[795.0878, 795.0878, 795.0878],\n",
            "                        std=[460.0955, 460.0955, 460.0955],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='DefaultFormatBundle'),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        version='le90',\n",
            "        data_root='./val'),\n",
            "    test=dict(\n",
            "        type='MAFATDataset',\n",
            "        ann_file='labelTxt',\n",
            "        img_prefix='images',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1024, 1024),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='RResize'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[795.0878, 795.0878, 795.0878],\n",
            "                        std=[460.0955, 460.0955, 460.0955],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='DefaultFormatBundle'),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        version='le90',\n",
            "        data_root='./val'))\n",
            "evaluation = dict(interval=2, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=4)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(\n",
            "    interval=2,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = 'redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "angle_version = 'le90'\n",
            "model = dict(\n",
            "    type='ReDet',\n",
            "    backbone=dict(\n",
            "        type='ReResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        style='pytorch',\n",
            "        pretrained='work_dirs/pretrain/re_resnet50_c8_batch256-25b16846.pth'),\n",
            "    neck=dict(\n",
            "        type='ReFPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RotatedRPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        version='le90',\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='RoITransRoIHead',\n",
            "        version='le90',\n",
            "        num_stages=2,\n",
            "        stage_loss_weights=[1, 1],\n",
            "        bbox_roi_extractor=[\n",
            "            dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            dict(\n",
            "                type='RotatedSingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RiRoIAlignRotated',\n",
            "                    out_size=7,\n",
            "                    num_samples=2,\n",
            "                    num_orientations=8,\n",
            "                    clockwise=True),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32])\n",
            "        ],\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='RotatedShared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=13,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHAHBBoxCoder',\n",
            "                    angle_range='le90',\n",
            "                    norm_factor=2,\n",
            "                    edge_swap=True,\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2, 1]),\n",
            "                reg_class_agnostic=True,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='RotatedShared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=13,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHAOBBoxCoder',\n",
            "                    angle_range='le90',\n",
            "                    norm_factor=None,\n",
            "                    edge_swap=True,\n",
            "                    proj_xy=True,\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1, 0.5]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1,\n",
            "                gpu_assign_thr=200),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=0,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=2000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1,\n",
            "                    iou_calculator=dict(type='BboxOverlaps2D')),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1,\n",
            "                    iou_calculator=dict(type='RBboxOverlaps2D')),\n",
            "                sampler=dict(\n",
            "                    type='RRandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)\n",
            "        ]),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=2000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            nms_pre=2000,\n",
            "            min_bbox_size=0,\n",
            "            score_thr=0.05,\n",
            "            nms=dict(iou_thr=0.1),\n",
            "            max_per_img=2000)))\n",
            "work_dir = './tutorial_exps'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "device = 'cuda'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "import os\n",
        "\n",
        "# # Modify dataset type and path\n",
        "cfg.dataset_type = 'MAFATDataset'\n",
        "cfg.data_root = './'\n",
        "\n",
        "cfg.img_norm_cfg = dict(type='Normalize',\n",
        "    mean=[795.0878, 795.0878, 795.0878], std=[460.0955, 460.0955, 460.0955], to_rgb=True)\n",
        "\n",
        "cfg.data.train.type = 'MAFATDataset'\n",
        "cfg.data.train.data_root = os.path.join(cfg.data_root, 'train')\n",
        "cfg.data.train.ann_file = 'labelTxt'\n",
        "cfg.data.train.img_prefix = 'images'\n",
        "color_type='unchanged'\n",
        "\n",
        "cfg.data.test.type = 'MAFATDataset'\n",
        "cfg.data.test.data_root = os.path.join(cfg.data_root, 'val')\n",
        "cfg.data.test.ann_file = 'labelTxt'\n",
        "cfg.data.test.img_prefix = 'images'\n",
        "\n",
        "cfg.data.val.type = 'MAFATDataset'\n",
        "cfg.data.val.data_root = os.path.join(cfg.data_root, 'val')\n",
        "cfg.data.val.ann_file = 'labelTxt'\n",
        "cfg.data.val.img_prefix = 'images'\n",
        "\n",
        "# edit pipeline to handle 16bit images\n",
        "cfg.train_pipeline[0].color_type = 'unchanged'\n",
        "cfg.train_pipeline[0].type = 'LoadImageFromFilePIL'\n",
        "cfg.test_pipeline[0].color_type = 'unchanged'\n",
        "cfg.test_pipeline[0].type = 'LoadImageFromFilePIL'\n",
        "\n",
        "cfg.data.train.pipeline[5] = cfg.img_norm_cfg\n",
        "cfg.data.val.pipeline[1]['transforms'][1] = cfg.img_norm_cfg\n",
        "cfg.data.test.pipeline[1]['transforms'][1] = cfg.img_norm_cfg\n",
        "\n",
        "# modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head[0].num_classes = len(CLASSES_ALL)\n",
        "cfg.model.roi_head.bbox_head[1].num_classes = len(CLASSES_ALL)\n",
        "# Load pre-trainied weights, trained on DOTA\n",
        "cfg.load_from = 'redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "cfg.optimizer.lr = 1e-3\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.runner.max_epochs = 4\n",
        "cfg.log_config.interval = 2\n",
        "\n",
        "cfg.data.samples_per_gpu=2\n",
        "cfg.data.workers_per_gpu=2\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 2\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 1\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.device='cuda'\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5XgPKwlhW24"
      },
      "outputs": [],
      "source": [
        "# save edited config file \n",
        "dump_file = \"my_config_redet.py\"\n",
        "cfg.dump(dump_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPSm8HuthcXp"
      },
      "source": [
        "### Train a new detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc6K5208hdNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14daf193-4e44-4aac-9cb9-60bce7b1b10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.4\n",
            "2.28.1\n",
            "11.6\n",
            "GCC 9.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmrotate/mmrotate/models/backbones/re_resnet.py:481: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
            "/usr/local/lib/python3.8/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  full_mask[mask] = norms.to(torch.uint8)\n",
            "/usr/local/lib/python3.8/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
            "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
            "2023-02-01 16:25:21,184 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2023-02-01 16:25:21,306 - mmdet - INFO - load checkpoint from local path: redet_re50_fpn_1x_dota_ms_rr_le90-fc9217b5.pth\n",
            "2023-02-01 16:25:21,436 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([16, 1024]) from checkpoint, the shape in current model is torch.Size([14, 1024]).\n",
            "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([14]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([16, 1024]) from checkpoint, the shape in current model is torch.Size([14, 1024]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([14]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_reg.weight: copying a param with shape torch.Size([75, 1024]) from checkpoint, the shape in current model is torch.Size([65, 1024]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_reg.bias: copying a param with shape torch.Size([75]) from checkpoint, the shape in current model is torch.Size([65]).\n",
            "missing keys in source state_dict: backbone.conv1.filter, backbone.layer2.0.conv1.filter, backbone.layer2.0.conv2.filter, backbone.layer2.0.conv3.filter, backbone.layer2.0.downsample.0.filter, backbone.layer2.1.conv1.filter, backbone.layer2.1.conv2.filter, backbone.layer2.1.conv3.filter, backbone.layer2.2.conv1.filter, backbone.layer2.2.conv2.filter, backbone.layer2.2.conv3.filter, backbone.layer2.3.conv1.filter, backbone.layer2.3.conv2.filter, backbone.layer2.3.conv3.filter, backbone.layer3.0.conv1.filter, backbone.layer3.0.conv2.filter, backbone.layer3.0.conv3.filter, backbone.layer3.0.downsample.0.filter, backbone.layer3.1.conv1.filter, backbone.layer3.1.conv2.filter, backbone.layer3.1.conv3.filter, backbone.layer3.2.conv1.filter, backbone.layer3.2.conv2.filter, backbone.layer3.2.conv3.filter, backbone.layer3.3.conv1.filter, backbone.layer3.3.conv2.filter, backbone.layer3.3.conv3.filter, backbone.layer3.4.conv1.filter, backbone.layer3.4.conv2.filter, backbone.layer3.4.conv3.filter, backbone.layer3.5.conv1.filter, backbone.layer3.5.conv2.filter, backbone.layer3.5.conv3.filter, backbone.layer4.0.conv1.filter, backbone.layer4.0.conv2.filter, backbone.layer4.0.conv3.filter, backbone.layer4.0.downsample.0.filter, backbone.layer4.1.conv1.filter, backbone.layer4.1.conv2.filter, backbone.layer4.1.conv3.filter, backbone.layer4.2.conv1.filter, backbone.layer4.2.conv2.filter, backbone.layer4.2.conv3.filter, neck.lateral_convs.0.conv.expanded_bias, neck.lateral_convs.0.conv.filter, neck.lateral_convs.1.conv.expanded_bias, neck.lateral_convs.1.conv.filter, neck.lateral_convs.2.conv.expanded_bias, neck.lateral_convs.2.conv.filter, neck.lateral_convs.3.conv.expanded_bias, neck.lateral_convs.3.conv.filter, neck.fpn_convs.0.conv.expanded_bias, neck.fpn_convs.0.conv.filter, neck.fpn_convs.1.conv.expanded_bias, neck.fpn_convs.1.conv.filter, neck.fpn_convs.2.conv.expanded_bias, neck.fpn_convs.2.conv.filter, neck.fpn_convs.3.conv.expanded_bias, neck.fpn_convs.3.conv.filter\n",
            "\n",
            "2023-02-01 16:25:21,439 - mmdet - INFO - Start running, host: root@22fdb9c10695, work_dir: /content/tutorial_exps\n",
            "2023-02-01 16:25:21,442 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "2023-02-01 16:25:21,444 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
            "2023-02-01 16:25:21,447 - mmdet - INFO - Checkpoints will be saved to /content/tutorial_exps by HardDiskBackend.\n",
            "/usr/local/lib/python3.8/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
            "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
            "2023-02-01 16:25:35,863 - mmdet - INFO - Epoch [1][2/18]\tlr: 1.000e-03, eta: 0:03:37, time: 3.112, data_time: 1.244, memory: 3685, loss_rpn_cls: 0.3578, loss_rpn_bbox: 0.0210, s0.loss_cls: 2.7610, s0.acc: 0.0977, s0.loss_bbox: 0.0451, s1.loss_cls: 2.5201, s1.acc: 7.7148, s1.loss_bbox: 0.0693, loss: 5.7744, grad_norm: 23.9104\n",
            "2023-02-01 16:25:37,987 - mmdet - INFO - Epoch [1][4/18]\tlr: 1.000e-03, eta: 0:02:21, time: 1.062, data_time: 0.014, memory: 3685, loss_rpn_cls: 0.9476, loss_rpn_bbox: 0.0567, s0.loss_cls: 2.1471, s0.acc: 63.3789, s0.loss_bbox: 0.0154, s1.loss_cls: 1.5473, s1.acc: 96.6309, s1.loss_bbox: 0.0024, loss: 4.7167, grad_norm: 24.4844\n",
            "2023-02-01 16:25:40,133 - mmdet - INFO - Epoch [1][6/18]\tlr: 1.000e-03, eta: 0:01:55, time: 1.073, data_time: 0.017, memory: 3685, loss_rpn_cls: 0.2979, loss_rpn_bbox: 0.0376, s0.loss_cls: 1.2919, s0.acc: 94.6777, s0.loss_bbox: 0.1256, s1.loss_cls: 0.7070, s1.acc: 95.7520, s1.loss_bbox: 0.1171, loss: 2.5771, grad_norm: 16.2089\n",
            "2023-02-01 16:25:42,262 - mmdet - INFO - Epoch [1][8/18]\tlr: 1.000e-03, eta: 0:01:40, time: 1.064, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.7524, loss_rpn_bbox: 0.0387, s0.loss_cls: 0.5162, s0.acc: 98.7305, s0.loss_bbox: 0.0189, s1.loss_cls: 0.2071, s1.acc: 98.8281, s1.loss_bbox: 0.0189, loss: 1.5523, grad_norm: 13.7330\n",
            "2023-02-01 16:25:44,412 - mmdet - INFO - Epoch [1][10/18]\tlr: 1.000e-03, eta: 0:01:31, time: 1.075, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.6158, loss_rpn_bbox: 0.0579, s0.loss_cls: 0.2290, s0.acc: 98.3887, s0.loss_bbox: 0.0411, s1.loss_cls: 0.1325, s1.acc: 98.7305, s1.loss_bbox: 0.0141, loss: 1.0905, grad_norm: 10.4746\n",
            "2023-02-01 16:25:46,589 - mmdet - INFO - Epoch [1][12/18]\tlr: 1.000e-03, eta: 0:01:24, time: 1.088, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.6250, loss_rpn_bbox: 0.0654, s0.loss_cls: 0.1729, s0.acc: 98.0957, s0.loss_bbox: 0.0213, s1.loss_cls: 0.1956, s1.acc: 98.0469, s1.loss_bbox: 0.0218, loss: 1.1021, grad_norm: 9.4573\n",
            "2023-02-01 16:25:48,680 - mmdet - INFO - Epoch [1][14/18]\tlr: 1.000e-03, eta: 0:01:18, time: 1.046, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.0836, loss_rpn_bbox: 0.0204, s0.loss_cls: 0.3416, s0.acc: 94.1406, s0.loss_bbox: 0.1293, s1.loss_cls: 0.4742, s1.acc: 93.6035, s1.loss_bbox: 0.2637, loss: 1.3128, grad_norm: 8.2588\n",
            "2023-02-01 16:25:50,680 - mmdet - INFO - Epoch [1][16/18]\tlr: 1.000e-03, eta: 0:01:13, time: 1.000, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.2113, loss_rpn_bbox: 0.0164, s0.loss_cls: 0.1352, s0.acc: 97.9980, s0.loss_bbox: 0.0438, s1.loss_cls: 0.1474, s1.acc: 98.0957, s1.loss_bbox: 0.0660, loss: 0.6200, grad_norm: 6.4948\n",
            "2023-02-01 16:25:52,655 - mmdet - INFO - Epoch [1][18/18]\tlr: 1.000e-03, eta: 0:01:09, time: 0.988, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.1849, loss_rpn_bbox: 0.0385, s0.loss_cls: 0.4147, s0.acc: 95.8008, s0.loss_bbox: 0.1562, s1.loss_cls: 0.2621, s1.acc: 97.6074, s1.loss_bbox: 0.0318, loss: 1.0882, grad_norm: 8.0257\n",
            "2023-02-01 16:25:52,741 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "2023-02-01 16:25:59,936 - mmdet - INFO - Epoch [2][2/18]\tlr: 1.000e-03, eta: 0:01:14, time: 2.729, data_time: 1.298, memory: 3685, loss_rpn_cls: 0.1725, loss_rpn_bbox: 0.0082, s0.loss_cls: 0.2075, s0.acc: 96.2891, s0.loss_bbox: 0.0282, s1.loss_cls: 0.4189, s1.acc: 94.6289, s1.loss_bbox: 0.2201, loss: 1.0555, grad_norm: 8.9098\n",
            "2023-02-01 16:26:02,089 - mmdet - INFO - Epoch [2][4/18]\tlr: 1.000e-03, eta: 0:01:09, time: 1.077, data_time: 0.016, memory: 3685, loss_rpn_cls: 0.1448, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.1531, s0.acc: 97.5098, s0.loss_bbox: 0.0245, s1.loss_cls: 0.2057, s1.acc: 97.0215, s1.loss_bbox: 0.1033, loss: 0.6457, grad_norm: 4.2813\n",
            "2023-02-01 16:26:04,193 - mmdet - INFO - Epoch [2][6/18]\tlr: 1.000e-03, eta: 0:01:05, time: 1.052, data_time: 0.014, memory: 3685, loss_rpn_cls: 0.1295, loss_rpn_bbox: 0.0419, s0.loss_cls: 0.1175, s0.acc: 98.4863, s0.loss_bbox: 0.0451, s1.loss_cls: 0.0965, s1.acc: 98.8770, s1.loss_bbox: 0.0227, loss: 0.4531, grad_norm: 3.7074\n",
            "2023-02-01 16:26:06,552 - mmdet - INFO - Epoch [2][8/18]\tlr: 1.000e-03, eta: 0:01:02, time: 1.179, data_time: 0.018, memory: 3685, loss_rpn_cls: 0.1687, loss_rpn_bbox: 0.0428, s0.loss_cls: 0.1639, s0.acc: 97.9004, s0.loss_bbox: 0.0315, s1.loss_cls: 0.1573, s1.acc: 97.9980, s1.loss_bbox: 0.0512, loss: 0.6152, grad_norm: 4.1051\n",
            "2023-02-01 16:26:09,054 - mmdet - INFO - Epoch [2][10/18]\tlr: 1.000e-03, eta: 0:00:59, time: 1.251, data_time: 0.015, memory: 3685, loss_rpn_cls: 0.1363, loss_rpn_bbox: 0.0340, s0.loss_cls: 0.1786, s0.acc: 97.5098, s0.loss_bbox: 0.0513, s1.loss_cls: 0.1432, s1.acc: 98.0469, s1.loss_bbox: 0.0555, loss: 0.5989, grad_norm: 3.4009\n",
            "2023-02-01 16:26:11,215 - mmdet - INFO - Epoch [2][12/18]\tlr: 1.000e-03, eta: 0:00:55, time: 1.081, data_time: 0.013, memory: 3685, loss_rpn_cls: 0.1384, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.1144, s0.acc: 99.0234, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0794, s1.acc: 99.2676, s1.loss_bbox: 0.0041, loss: 0.3792, grad_norm: 3.0865\n",
            "2023-02-01 16:26:13,355 - mmdet - INFO - Epoch [2][14/18]\tlr: 1.000e-03, eta: 0:00:52, time: 1.070, data_time: 0.015, memory: 3685, loss_rpn_cls: 0.0787, loss_rpn_bbox: 0.0264, s0.loss_cls: 0.3407, s0.acc: 92.1875, s0.loss_bbox: 0.0706, s1.loss_cls: 0.3308, s1.acc: 92.1160, s1.loss_bbox: 0.2621, loss: 1.1092, grad_norm: 3.6627\n",
            "2023-02-01 16:26:15,369 - mmdet - INFO - Epoch [2][16/18]\tlr: 1.000e-03, eta: 0:00:49, time: 1.007, data_time: 0.012, memory: 3685, loss_rpn_cls: 0.0771, loss_rpn_bbox: 0.0277, s0.loss_cls: 0.1159, s0.acc: 98.5840, s0.loss_bbox: 0.0344, s1.loss_cls: 0.0788, s1.acc: 99.3164, s1.loss_bbox: 0.0034, loss: 0.3374, grad_norm: 2.8089\n",
            "2023-02-01 16:26:17,388 - mmdet - INFO - Epoch [2][18/18]\tlr: 1.000e-03, eta: 0:00:45, time: 1.010, data_time: 0.012, memory: 3685, loss_rpn_cls: 0.1069, loss_rpn_bbox: 0.0215, s0.loss_cls: 0.2632, s0.acc: 95.8496, s0.loss_bbox: 0.0541, s1.loss_cls: 0.2582, s1.acc: 95.4102, s1.loss_bbox: 0.0928, loss: 0.7968, grad_norm: 3.7868\n",
            "2023-02-01 16:26:17,512 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
            "2023-02-01 16:26:23,786 - mmdet - INFO - Epoch [3][2/18]\tlr: 1.000e-03, eta: 0:00:45, time: 2.399, data_time: 1.257, memory: 3685, loss_rpn_cls: 0.1407, loss_rpn_bbox: 0.0623, s0.loss_cls: 0.4304, s0.acc: 90.8691, s0.loss_bbox: 0.1333, s1.loss_cls: 0.4359, s1.acc: 89.9649, s1.loss_bbox: 0.2932, loss: 1.4958, grad_norm: 5.5725\n",
            "2023-02-01 16:26:25,912 - mmdet - INFO - Epoch [3][4/18]\tlr: 1.000e-03, eta: 0:00:42, time: 1.063, data_time: 0.017, memory: 3685, loss_rpn_cls: 0.0798, loss_rpn_bbox: 0.0205, s0.loss_cls: 0.1629, s0.acc: 97.4609, s0.loss_bbox: 0.0478, s1.loss_cls: 0.1377, s1.acc: 98.1445, s1.loss_bbox: 0.0628, loss: 0.5115, grad_norm: 2.8761\n",
            "2023-02-01 16:26:28,041 - mmdet - INFO - Epoch [3][6/18]\tlr: 1.000e-03, eta: 0:00:39, time: 1.064, data_time: 0.016, memory: 3685, loss_rpn_cls: 0.0876, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1279, s0.acc: 97.7051, s0.loss_bbox: 0.0525, s1.loss_cls: 0.1257, s1.acc: 97.4121, s1.loss_bbox: 0.0843, loss: 0.4952, grad_norm: 2.6138\n",
            "2023-02-01 16:26:30,206 - mmdet - INFO - Epoch [3][8/18]\tlr: 1.000e-03, eta: 0:00:36, time: 1.082, data_time: 0.016, memory: 3685, loss_rpn_cls: 0.1626, loss_rpn_bbox: 0.0416, s0.loss_cls: 0.3329, s0.acc: 93.6035, s0.loss_bbox: 0.0627, s1.loss_cls: 0.3667, s1.acc: 92.3340, s1.loss_bbox: 0.2402, loss: 1.2067, grad_norm: 4.1626\n",
            "2023-02-01 16:26:32,381 - mmdet - INFO - Epoch [3][10/18]\tlr: 1.000e-03, eta: 0:00:33, time: 1.088, data_time: 0.015, memory: 3685, loss_rpn_cls: 0.0579, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0844, s0.acc: 98.9258, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0818, s1.acc: 99.1211, s1.loss_bbox: 0.0330, loss: 0.2763, grad_norm: 2.2938\n",
            "2023-02-01 16:26:34,538 - mmdet - INFO - Epoch [3][12/18]\tlr: 1.000e-03, eta: 0:00:30, time: 1.078, data_time: 0.015, memory: 3685, loss_rpn_cls: 0.0828, loss_rpn_bbox: 0.0289, s0.loss_cls: 0.3043, s0.acc: 94.3359, s0.loss_bbox: 0.1204, s1.loss_cls: 0.2868, s1.acc: 94.5801, s1.loss_bbox: 0.2561, loss: 1.0792, grad_norm: 3.3792\n",
            "2023-02-01 16:26:36,683 - mmdet - INFO - Epoch [3][14/18]\tlr: 1.000e-03, eta: 0:00:27, time: 1.072, data_time: 0.017, memory: 3685, loss_rpn_cls: 0.0619, loss_rpn_bbox: 0.0225, s0.loss_cls: 0.3969, s0.acc: 91.3574, s0.loss_bbox: 0.1133, s1.loss_cls: 0.3663, s1.acc: 91.5114, s1.loss_bbox: 0.2748, loss: 1.2358, grad_norm: 4.5610\n",
            "2023-02-01 16:26:38,724 - mmdet - INFO - Epoch [3][16/18]\tlr: 1.000e-03, eta: 0:00:25, time: 1.020, data_time: 0.013, memory: 3686, loss_rpn_cls: 0.1043, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.2556, s0.acc: 96.2402, s0.loss_bbox: 0.0635, s1.loss_cls: 0.2203, s1.acc: 96.7285, s1.loss_bbox: 0.1148, loss: 0.7771, grad_norm: 3.9085\n",
            "2023-02-01 16:26:40,723 - mmdet - INFO - Epoch [3][18/18]\tlr: 1.000e-03, eta: 0:00:22, time: 1.000, data_time: 0.012, memory: 3686, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0093, s0.loss_cls: 0.0857, s0.acc: 98.9258, s0.loss_bbox: 0.0210, s1.loss_cls: 0.0783, s1.acc: 99.0234, s1.loss_bbox: 0.0268, loss: 0.2699, grad_norm: 1.9435\n",
            "2023-02-01 16:26:40,857 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
            "2023-02-01 16:26:47,053 - mmdet - INFO - Epoch [4][2/18]\tlr: 1.000e-03, eta: 0:00:20, time: 2.414, data_time: 1.266, memory: 3686, loss_rpn_cls: 0.0483, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.2861, s0.acc: 92.4316, s0.loss_bbox: 0.0676, s1.loss_cls: 0.2665, s1.acc: 92.3277, s1.loss_bbox: 0.2336, loss: 0.9177, grad_norm: 2.8362\n",
            "2023-02-01 16:26:49,176 - mmdet - INFO - Epoch [4][4/18]\tlr: 1.000e-03, eta: 0:00:18, time: 1.062, data_time: 0.014, memory: 3686, loss_rpn_cls: 0.0684, loss_rpn_bbox: 0.0241, s0.loss_cls: 0.4728, s0.acc: 90.1855, s0.loss_bbox: 0.1725, s1.loss_cls: 0.4579, s1.acc: 90.2344, s1.loss_bbox: 0.2678, loss: 1.4635, grad_norm: 5.2361\n",
            "2023-02-01 16:26:51,318 - mmdet - INFO - Epoch [4][6/18]\tlr: 1.000e-03, eta: 0:00:15, time: 1.071, data_time: 0.014, memory: 3686, loss_rpn_cls: 0.0576, loss_rpn_bbox: 0.0111, s0.loss_cls: 0.1361, s0.acc: 97.8516, s0.loss_bbox: 0.0527, s1.loss_cls: 0.0886, s1.acc: 99.0723, s1.loss_bbox: 0.0210, loss: 0.3671, grad_norm: 2.9592\n",
            "2023-02-01 16:26:53,461 - mmdet - INFO - Epoch [4][8/18]\tlr: 1.000e-03, eta: 0:00:12, time: 1.071, data_time: 0.015, memory: 3686, loss_rpn_cls: 0.1676, loss_rpn_bbox: 0.0477, s0.loss_cls: 0.3241, s0.acc: 94.4824, s0.loss_bbox: 0.0827, s1.loss_cls: 0.3125, s1.acc: 94.6777, s1.loss_bbox: 0.1979, loss: 1.1326, grad_norm: 4.3549\n",
            "2023-02-01 16:26:55,601 - mmdet - INFO - Epoch [4][10/18]\tlr: 1.000e-03, eta: 0:00:10, time: 1.070, data_time: 0.016, memory: 3686, loss_rpn_cls: 0.0313, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.1043, s0.acc: 98.5352, s0.loss_bbox: 0.0216, s1.loss_cls: 0.1112, s1.acc: 98.3887, s1.loss_bbox: 0.0614, loss: 0.3364, grad_norm: 1.8452\n",
            "2023-02-01 16:26:57,735 - mmdet - INFO - Epoch [4][12/18]\tlr: 1.000e-03, eta: 0:00:07, time: 1.067, data_time: 0.015, memory: 3686, loss_rpn_cls: 0.1121, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1943, s0.acc: 96.4844, s0.loss_bbox: 0.0399, s1.loss_cls: 0.2249, s1.acc: 95.4590, s1.loss_bbox: 0.1496, loss: 0.7366, grad_norm: 3.2682\n",
            "2023-02-01 16:26:59,905 - mmdet - INFO - Epoch [4][14/18]\tlr: 1.000e-03, eta: 0:00:05, time: 1.085, data_time: 0.016, memory: 3686, loss_rpn_cls: 0.0941, loss_rpn_bbox: 0.0297, s0.loss_cls: 0.3292, s0.acc: 94.3359, s0.loss_bbox: 0.0881, s1.loss_cls: 0.3075, s1.acc: 94.6777, s1.loss_bbox: 0.2170, loss: 1.0657, grad_norm: 3.9538\n",
            "2023-02-01 16:27:01,948 - mmdet - INFO - Epoch [4][16/18]\tlr: 1.000e-03, eta: 0:00:02, time: 1.022, data_time: 0.013, memory: 3686, loss_rpn_cls: 0.0654, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.1890, s0.acc: 96.6309, s0.loss_bbox: 0.0556, s1.loss_cls: 0.1880, s1.acc: 96.8262, s1.loss_bbox: 0.1286, loss: 0.6415, grad_norm: 2.5753\n",
            "2023-02-01 16:27:04,010 - mmdet - INFO - Epoch [4][18/18]\tlr: 1.000e-03, eta: 0:00:00, time: 1.031, data_time: 0.012, memory: 3686, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.2470, s0.acc: 93.5059, s0.loss_bbox: 0.0456, s1.loss_cls: 0.2869, s1.acc: 91.3086, s1.loss_bbox: 0.2575, loss: 0.8669, grad_norm: 4.2638\n",
            "2023-02-01 16:27:04,143 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
          ]
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "import mmcv\n",
        "collect_env()\n",
        "\n",
        "# Check MMRotate installation\n",
        "import mmrotate\n",
        "print(mmrotate.__version__)\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=False)\n",
        "# train_detector(model, datasets, cfg, distributed=False, validate=True) # doesn't work in colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mkIAOWNh6x-"
      },
      "source": [
        "## Deploy a model for submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ1CK7DLXtMF"
      },
      "source": [
        "###Create model file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkWxvJWIh9Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9460be72-d22b-4122-c3f9-0e32081526a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmrotate.apis import inference_detector_by_patches\n",
        "from mmrotate.models import build_detector\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "\n",
        "class model():\n",
        "    def __init__(self):\n",
        "        self.make_initial_pass_over_dataset = True\n",
        "        self.CLASSES = ('small_vehicle','bus','medium_vehicle','large_vehicle',\n",
        "     'double_trailer_truck','small_aircraft','large_aircraft','small_vessel','medium_vessel','large_vessel',\n",
        "     'heavy_equipment', 'container','pylon', ) # MAFAT classes\n",
        "        self.stats = []\n",
        "        self.checkpoint_path = r\"latest.pth\"\n",
        "        self.config_path = r\"my_config_redet.py\"\n",
        "        # Initialize variables to store the running sum and square sum of pixel values\n",
        "        self.running_sum = 0\n",
        "        self.running_square_sum = 0\n",
        "        # Initialize a variable to store the number of images processed\n",
        "        self.num_images = 0\n",
        "    \n",
        "    def collect_statistics_iter(self, img, meta):\n",
        "        '''img is a grayscale 16bit image of size 1280x1280 pixels (as numpy array).\n",
        "        \n",
        "        \n",
        "        metadata is a dictionary with the metadata for the given image\n",
        "        (similar to training phase, but without AOI and Hermetic data)\n",
        "        '''\n",
        "        # you can do something with the meta data\n",
        "        \n",
        "        # calculate mean and std using welford method        \n",
        "        self.mean_and_std(img) \n",
        "        \n",
        "        \n",
        "        \n",
        "    def update_model(self):\n",
        "        # get mean and std\n",
        "        self.std *= 2 ** 16\n",
        "        self.mean *= 2 ** 16\n",
        "        \n",
        "        print(\"mean: %f, std: %f\" % (self.mean, self.std))\n",
        "        self.stats.append(self.mean)\n",
        "        self.stats.append(self.std)\n",
        "        \n",
        "        # update test pipeline with computed statistics\n",
        "        self.model.cfg.data.test.pipeline[1]['transforms'][1]['mean'] = [self.stats[0]]*3\n",
        "        self.model.cfg.data.test.pipeline[1]['transforms'][1]['std'] = [self.stats[1]]*3\n",
        "        \n",
        "    \n",
        "    def mean_and_std(self, image):\n",
        "        \n",
        "        # Update the running sum and square sum with the new image data\n",
        "        image = image / 2 ** 16\n",
        "        self.running_sum += image.sum()\n",
        "        self.running_square_sum += (image ** 2).sum()\n",
        "\n",
        "        # Increment the number of images processed\n",
        "        self.num_images += 1\n",
        "\n",
        "        # Compute the mean and standard deviation on the fly\n",
        "        self.mean = self.running_sum / (self.num_images * image.shape[0] * image.shape[1])\n",
        "        self.std = np.sqrt((self.running_square_sum / (self.num_images * image.shape[0] * image.shape[1])) - self.mean**2)\n",
        "        \n",
        " \n",
        "    \n",
        "    \n",
        "    def load(self, dir_path):\n",
        "        \"\"\"loads the model.\n",
        "        dir_path is for internal use only - do not remove it.\n",
        "        all other paths, such as self.config_path should only contain the file name (in this case: my_config_redet.py).\n",
        "        these paths must be concatenated with dir_path - see example in the code below\n",
        "        make sure these files are in the same directory as the model.py file\n",
        "\n",
        "        Args:\n",
        "            dir_path (string): path to the submission directory (for internal use only).\n",
        "        \"\"\"        \n",
        "        # check if directory contains a zip file, i.e. the model weights were downloaded from google drive\n",
        "        files = os.listdir(dir_path)\n",
        "        for filename in files:\n",
        "            if filename.endswith(\"zip\"):\n",
        "                with ZipFile(os.path.join(dir_path, filename), 'r') as z:\n",
        "                    z.extractall(dir_path)\n",
        "                break\n",
        "            \n",
        "        # join paths\n",
        "        config_path = os.path.join(dir_path, self.config_path)\n",
        "        checkpoint_path = os.path.join(dir_path, self.checkpoint_path)\n",
        "        # Set the device to be used for evaluation\n",
        "        self.device='cuda:0'\n",
        "\n",
        "        # Load the config\n",
        "        self.config = mmcv.Config.fromfile(config_path)\n",
        "        # adjust number of classes\n",
        "        # self.config.model.bbox_head.num_classes = len(CLASSES_ALL)\n",
        "        # Set pretrained to be None since we do not need pretrained model here\n",
        "        self.config.model.pretrained = None\n",
        "\n",
        "        # Initialize the detector\n",
        "        self.model = build_detector(self.config.model)\n",
        "\n",
        "        # Load checkpoint\n",
        "        self.checkpoint = load_checkpoint(self.model, checkpoint_path, map_location=self.device)\n",
        "\n",
        "        # Set the classes of models for inference\n",
        "        self.model.CLASSES = self.checkpoint['meta']['CLASSES']\n",
        "\n",
        "        # We need to set the model's cfg for inference\n",
        "        self.model.cfg = self.config\n",
        "\n",
        "        # Convert the model to GPU\n",
        "        self.model.to(self.device)\n",
        "        # Convert the model into evaluation mode\n",
        "        self.model.eval()\n",
        "        \n",
        "    def predict(self, img, metadata=None):\n",
        "        '''img is a grayscale 16bit image of size 1280x1280 pixels.\n",
        "            expected output is a list of lists. each sub list represents all the detections for a class.\n",
        "            the sub lists need to be in the same order as self.CLASSES.\n",
        "            the detections need to be in the form of:\n",
        "            confidence x1 y1 x2 y2 x3 y3 x4 y4\n",
        "            \n",
        "            metadata is a dictionary with the metadata for the given image\n",
        "            (similar to training phase, but without AOI and Hermetic data)\n",
        "        '''\n",
        "            \n",
        "        # the DNN expects a RGB image, we duplicate the grayscale image 3 times\n",
        "        img = np.stack((img, )*3, axis=-1)\n",
        "        # pass the image through the model to get detections\n",
        "        result = inference_detector_by_patches(self.model, img, [640], [320], [1.0], 0.3)\n",
        "        # result = inference_detector(self.model, img)\n",
        "        for i, res in enumerate(result):\n",
        "            result[i] = self.convert_rbb2polygon(res)\n",
        "        return result\n",
        "    \n",
        "    def convert_rbb2polygon(self, bboxes):\n",
        "        polygons = []\n",
        "        for i, bbox in enumerate(bboxes):\n",
        "            xc, yc, w, h, ag, conf = bbox\n",
        "            wx, wy = w / 2 * np.cos(ag), w / 2 * np.sin(ag)\n",
        "            hx, hy = -h / 2 * np.sin(ag), h / 2 * np.cos(ag)\n",
        "            p1 = (xc - wx - hx, yc - wy - hy)\n",
        "            p2 = (xc + wx - hx, yc + wy - hy)\n",
        "            p3 = (xc + wx + hx, yc + wy + hy)\n",
        "            p4 = (xc - wx + hx, yc - wy + hy)\n",
        "            poly = np.array([conf, p1[0], p1[1], p2[0], p2[1], p3[0], p3[1], p4[0], p4[1]])\n",
        "            polygons.append(poly)\n",
        "        return polygons\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDDWOhNbXyK9"
      },
      "source": [
        "###create metadata file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpLZn2CQm-RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e1b817-bdac-4de9-e73e-66277b643fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metadata\n"
          ]
        }
      ],
      "source": [
        "%%writefile metadata\n",
        "command: python3 $program/model.py $input $output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH_vQzdBoPww"
      },
      "source": [
        "### Option 1 - weights size is small (total submission size under 300Mb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKCrVtkV8Qq"
      },
      "outputs": [],
      "source": [
        "!cp tutorial_exps/epoch_4.pth ./latest.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZfepwyjnJvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ac6d81-1384-4f45-ee67-ef717cc28e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model.py (deflated 66%)\n",
            "  adding: my_config_redet.py (deflated 79%)\n",
            "  adding: latest.pth (deflated 8%)\n",
            "  adding: metadata (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r submission_regular.zip model.py my_config_redet.py latest.pth metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLiKcNlVopWY"
      },
      "source": [
        "###Option 2 - weights size is large (total submission size over 300Mb and under 1 Gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-GPpY6kA6tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3c6986-ac5b-436c-aa26-050922888653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: latest.pth (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r weights.zip latest.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z403wXooz1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbe105c-7f31-456b-ee71-4194bc587faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_url.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_url.txt\n",
        "https://drive.google.com/file/d/1Y-L9CLqN7WVdm1nEdu6Lt7okyoCbjbx4/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfV4KcgOpNXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b82bac-1076-4988-eff3-fa5022384565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model.py (deflated 66%)\n",
            "  adding: my_config_redet.py (deflated 79%)\n",
            "  adding: model_url.txt (stored 0%)\n",
            "  adding: metadata (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r submission_url.zip model.py my_config_redet.py model_url.txt metadata"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "y-krTp6T8TeL",
        "WK4qlrj8D0hk",
        "WkHH7-5HOFNT",
        "VDRzOpzHHTyb",
        "jXeb_p0PN3LZ",
        "QJVluHjBf5Un",
        "ifKK_MNzDjM9",
        "Lw59UK_JDspH",
        "9KUbahHYgSJv",
        "0HFeWHcnhHmS",
        "SPSm8HuthcXp"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}